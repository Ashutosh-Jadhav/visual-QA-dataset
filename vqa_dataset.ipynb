{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AoeDIVmdxeJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import os\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    \"image_mappings_path\": \"abo-images-small/images/metadata/images.csv\",\n",
        "    \"listings_dir\": \"abo-listings/listings/metadata\",\n",
        "    \"output_dir\": \"output\",\n",
        "    \"image_base_path\": \"abo-images-small/images/small\",  # Updated base path\n",
        "    \"max_items\": 10,\n",
        "    \"model_name\": \"llava-hf/llava-1.5-7b-hf\"\n",
        "}\n",
        "\n",
        "def load_image_mappings():\n",
        "    \"\"\"Load image_id to path mappings from CSV\"\"\"\n",
        "    print(f\"üìÇ Loading image mappings from {CONFIG['image_mappings_path']}\")\n",
        "    try:\n",
        "        df = pd.read_csv(CONFIG['image_mappings_path'])\n",
        "        return dict(zip(df['image_id'], df['path']))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading image mappings: {e}\")\n",
        "        raise\n",
        "\n",
        "def initialize_llava():\n",
        "    \"\"\"Initialize LLaVA model with error handling\"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"‚öôÔ∏è Initializing LLaVA on {device}\")\n",
        "\n",
        "    try:\n",
        "        model = LlavaForConditionalGeneration.from_pretrained(\n",
        "            CONFIG[\"model_name\"],\n",
        "            torch_dtype=torch.float16,\n",
        "            low_cpu_mem_usage=True\n",
        "        ).to(device)\n",
        "        processor = AutoProcessor.from_pretrained(CONFIG[\"model_name\"])\n",
        "        return processor, model, device\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize LLaVA: {e}\")\n",
        "        raise\n",
        "\n",
        "def generate_vqa(image_path, metadata, processor, model):\n",
        "    \"\"\"Generate Q&A pair using LLaVA with proper image handling\"\"\"\n",
        "    try:\n",
        "        # Prepare the prompt\n",
        "        meta_text = \", \".join(f\"{k}: {v}\" for k, v in metadata.items() if v)\n",
        "        prompt = (\n",
        "            \"<image>\\n\"\n",
        "            f\"Product details: {meta_text}\\n\"\n",
        "            \"Generate a very specific one-word answer question about this product.\\n\"\n",
        "            \"Format: 'Question: What is the [specific attribute]? Answer: [One word]'\"\n",
        "        )\n",
        "\n",
        "        # Process image correctly\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Correct way to call the processor\n",
        "        inputs = processor(\n",
        "            text=prompt,\n",
        "            images=image,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True\n",
        "        ).to(model.device)\n",
        "\n",
        "        # Generate output\n",
        "        outputs = model.generate(**inputs, max_new_tokens=50, temperature=0.2)\n",
        "        result = processor.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Parse the output\n",
        "        if \"Question:\" in result and \"Answer:\" in result:\n",
        "            question = result.split(\"Question:\")[1].split(\"Answer:\")[0].strip()\n",
        "            answer = result.split(\"Answer:\")[1].strip().split()[0].rstrip('.,!?;:').capitalize()\n",
        "            return question, answer\n",
        "        return None, None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error generating VQA for {image_path}: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def process_listings():\n",
        "    \"\"\"Main processing pipeline\"\"\"\n",
        "    # Initialize components\n",
        "    image_mappings = load_image_mappings()\n",
        "    processor, model, device = initialize_llava()\n",
        "\n",
        "    # Prepare output directory\n",
        "    Path(CONFIG['output_dir']).mkdir(parents=True, exist_ok=True)\n",
        "    output_csv = os.path.join(CONFIG['output_dir'], \"vqa_dataset.csv\")\n",
        "\n",
        "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"image_path\", \"question\", \"answer\", \"item_id\", \"metadata\"])\n",
        "\n",
        "        processed = 0\n",
        "        for listing_file in Path(CONFIG['listings_dir']).glob(\"*.json\"):\n",
        "            print(f\"\\nüìÑ Processing {listing_file.name}...\")\n",
        "            with open(listing_file, 'r', encoding='utf-8') as f:\n",
        "                for line in f:\n",
        "                    if processed >= CONFIG['max_items']:\n",
        "                        break\n",
        "\n",
        "                    try:\n",
        "                        item = json.loads(line)\n",
        "                        img_id = item.get('main_image_id') or next(iter(item.get('other_image_id', [])), None)\n",
        "                        if not img_id:\n",
        "                            continue\n",
        "\n",
        "                        # Construct image path using the base path\n",
        "                        relative_path = image_mappings.get(img_id)\n",
        "                        if not relative_path:\n",
        "                            continue\n",
        "\n",
        "                        img_path = Path(CONFIG['image_base_path']) / relative_path\n",
        "                        if not img_path.exists():\n",
        "                            print(f\"‚ö†Ô∏è Image not found: {img_path}\")\n",
        "                            continue\n",
        "\n",
        "                        # Prepare metadata\n",
        "                        metadata = {\n",
        "                            'title': next((x['value'] for x in item.get('item_name', [])\n",
        "                                         if isinstance(x, dict) and x.get('language_tag', '').startswith('en')), None),\n",
        "                            'brand': next((x['value'] for x in item.get('brand', [])\n",
        "                                         if isinstance(x, dict) and x.get('language_tag', '').startswith('en')), None),\n",
        "                            'color': next((x['value'] for x in item.get('color', [])\n",
        "                                         if isinstance(x, dict) and x.get('language_tag', '').startswith('en')), None),\n",
        "                            'product_type': item.get('product_type', [{}])[0].get('value') if isinstance(item.get('product_type', []), list) else None,\n",
        "                            'item_id': item.get('item_id')\n",
        "                        }\n",
        "\n",
        "                        # Generate VQA pair\n",
        "                        question, answer = generate_vqa(img_path, metadata, processor, model)\n",
        "                        if question and answer:\n",
        "                            writer.writerow([\n",
        "                                str(img_path),\n",
        "                                question,\n",
        "                                answer,\n",
        "                                metadata['item_id'],\n",
        "                                json.dumps(metadata)\n",
        "                            ])\n",
        "                            processed += 1\n",
        "                            if processed % 10 == 0:\n",
        "                                print(f\"‚úÖ Processed {processed} items\")\n",
        "                                csvfile.flush()\n",
        "\n",
        "                    except json.JSONDecodeError:\n",
        "                        continue\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Unexpected error: {e}\")\n",
        "\n",
        "    print(f\"\\nüéâ Finished processing {processed} items\")\n",
        "    print(f\"üíæ Output saved to {output_csv}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_listings()"
      ]
    }
  ]
}